# URL do Ollama (local para testes)
OLLAMA_API_URL=http://localhost:11434

# Modelo a usar
MODEL=flux:latest

# Porta
PORT=5000

# Configurações Ollama
OLLAMA_NUM_PARALLEL=1
OLLAMA_NUM_GPU=0
